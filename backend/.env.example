# CXPM AI PRD Backend Configuration
# Copy this file to .env and fill in your values:
#   cp .env.example .env

# ===========================================
# LLM Configuration
# ===========================================

# Circuit API (Cisco's AI platform - primary provider)
# The {model} placeholder in the URL will be replaced with CIRCUIT_MODEL
CIRCUIT_BASE_URL=https://chat-ai.cisco.com/openai/deployments/{model}/chat/completions
CIRCUIT_MODEL=gpt-4.1
CIRCUIT_CLIENT_ID=your-client-id-here
CIRCUIT_CLIENT_SECRET=your-client-secret-here
CIRCUIT_APP_KEY=your-app-key-here

# Ollama (local LLM - fallback provider)
# Make sure Ollama is running: ollama serve
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ===========================================
# Database Configuration
# ===========================================

# SQLite database path (default)
DATABASE_URL=sqlite:///./cxpm.db

# ===========================================
# Application Settings
# ===========================================

# Maximum file upload size in KB
MAX_FILE_SIZE_KB=50

# LLM request timeout in seconds
LLM_TIMEOUT=60

# Maximum retry attempts for LLM calls
LLM_MAX_RETRIES=1

# Text chunk size for processing long documents (in characters)
CHUNK_SIZE_CHARS=4000

# ===========================================
# Jira Configuration
# ===========================================

# Jira instance base URL
JIRA_BASE_URL=https://cisco-cxe.atlassian.net/

# Jira API token (get from: https://id.atlassian.com/manage-profile/security/api-tokens)
JIRA_API_KEY=your-jira-api-token-here

# Jira user email
JIRA_USER=your-email@cisco.com
